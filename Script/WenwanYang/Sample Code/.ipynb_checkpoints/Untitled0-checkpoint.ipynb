{
 "metadata": {
  "name": "",
  "signature": "sha256:c04a5a4ec8695b7ec373d0093f1317edc306c1e9ada0c68a9e886ec4b71689d6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "from collections import Counter\n",
      "try:\n",
      "    import xml.etree.cElementTree as ET\n",
      "except ImportError:\n",
      "    import xml.etree.ElementTree as ET\n",
      "import numpy as np\n",
      "from scipy import sparse\n",
      "os.chdir(\"/Users/Vivian/Desktop/data\")\n",
      "import util\n",
      "import pandas as pd\n",
      "import time\n",
      "import sys\n",
      "\n",
      "#bread and butter\n",
      "import nltk\n",
      "import numpy as np\n",
      "from scipy import stats\n",
      "from scipy import sparse\n",
      "\n",
      "#toyz\n",
      "from sklearn import cross_validation as cv\n",
      "from sklearn import ensemble as es\n",
      "import util\n",
      "import pandas as pd\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###############################################\n",
      "#### 1. Auxilliary Funcs #######################\n",
      "################################################\n",
      "def print_full(x):\n",
      "    #print all rows of a panda dataframe\n",
      "    pd.set_option('display.max_rows', len(x))\n",
      "    print(x)\n",
      "    pd.reset_option('display.max_rows')\n",
      "\n",
      "\n",
      "def Accuracy(clf_preds, t_train):\n",
      "    clf_missId = ((clf_preds - t_train) != 0)\n",
      "    clf_miss = t_train[(clf_preds - t_train) != 0]\n",
      "    \n",
      "    rate = 1 - np.mean(clf_missId) #error rate\n",
      "    return rate, clf_miss\n",
      "\n",
      "def name_for_feature(command, t_train, X_train, feature_dict):\n",
      "    try:\n",
      "        col_id = feature_dict[command]\n",
      "    except KeyError:\n",
      "        print (\"command not exist\")\n",
      "        raise KeyError\n",
      "        \n",
      "    t_train = t_train.reshape(1, np.max(t_train.shape))\n",
      "    ftData = X_train.T[col_id]\n",
      "\n",
      "    nmIdx = t_train[np.array(ftData>0)]\n",
      "    out = [util.malware_classes[i] for i in nmIdx]\n",
      "    out = stats.itemfreq(out)\n",
      "    \n",
      "    return out\n",
      "\n",
      "\n",
      "def pruneFeatures(minFreq, X_train_dense, global_feat_dict):\n",
      "    print \"pruning training features...\"\n",
      "    sys.stdout.flush()\n",
      "\n",
      "    #featureFreq = [sum(feature != 0) for feature in X_train_dense.T]\n",
      "    #featureFreq_pd = pd.Series(featureFreq, global_feat_dict.keys())\n",
      "    featureFreq = []\n",
      "    X_train_denseT = X_train_dense.T\n",
      "    i = 0\n",
      "    i_max = len(X_train_denseT)\n",
      "\n",
      "    for feature in X_train_denseT:\n",
      "        featureFreq.append(sum(feature != 0))\n",
      "        i += 1\n",
      "        if i % 5000 == 0: \n",
      "            print \"Obtaining featureFreq: \" + \\\n",
      "                    str(round(float(i)*100/i_max, 3)) + \"%\"\n",
      "\n",
      "    print \"obtaining prunId...\"\n",
      "    sys.stdout.flush()\n",
      "\n",
      "    prunId = []\n",
      "    i = 0\n",
      "    for item in featureFreq: \n",
      "        if item > minFreq: prunId.append(i)\n",
      "        i += 1\n",
      "        if i % 5000 == 0: \n",
      "            print \"Obtaining prunId: \" + \\\n",
      "                    str(round(float(i)*100/i_max, 3)) + \"%\"\n",
      "            sys.stdout.flush()\n",
      "        \n",
      "    print \"obtaining prunId...Done!\"\n",
      "    sys.stdout.flush()\n",
      "\n",
      "    print \"Pruning Design Matrix... \"; sys.stdout.flush()\n",
      "    X_train_prune = X_train_dense.T[prunId].T #update X\n",
      "    print \"Pruning Design Matrix...Done!\"\n",
      "\n",
      "    global_feat_dict_prune = Counter() #update global_feat_dict\n",
      "    \n",
      "    dictList = global_feat_dict.items()\n",
      "    dictList_prune = np.array(dictList)[np.array(prunId)]\n",
      "    \n",
      "    for i in range(len(dictList_prune)):\n",
      "        global_feat_dict_prune[dictList_prune[i][0]] = dictList_prune[i][1]\n",
      "        if i % 5000 == 0: \n",
      "            print \"Pruning feature dict: \" + \\\n",
      "                str(round(float(i)*100/len(dictList_prune), 3)) + \"%\"\n",
      "            sys.stdout.flush()\n",
      "\n",
      "    print \"done pruning training features!\"\n",
      "    return X_train_prune, global_feat_dict_prune, featureFreq, prunId\n",
      "\n",
      "    \n",
      "################################################\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "################################\n",
      "#### 2. IO functions\n",
      "################################\n",
      "\n",
      "def extract_feats(ffs, direc=\"train\", global_feat_dict=None):\n",
      "    \"\"\"\n",
      "    arguments:\n",
      "      ffs are a list of feature-functions.\n",
      "      direc is a directory containing xml files (expected to be train or test).\n",
      "      global_feat_dict is a dictionary mapping feature_names to column-numbers; it\n",
      "      should only be provided when extracting features from test data, so that \n",
      "      the columns of the test matrix align correctly.\n",
      "\n",
      "    returns: \n",
      "      a sparse design matrix, a dict mapping features to column-numbers,\n",
      "      a vector of target classes, and a list of system-call-history ids in order \n",
      "      of their rows in the design matrix.\n",
      "      \n",
      "      Note: the vector of target classes returned will contain the true indices of the\n",
      "      target classes on the training data, but will contain only -1's on the test\n",
      "      data\n",
      "    \"\"\"\n",
      "    \n",
      "    fds = [] # list of feature dicts\n",
      "    classes = []\n",
      "    ids = [] \n",
      "    \n",
      "    i = 0\n",
      "    N = str(len(os.listdir(direc)))\n",
      "    \n",
      "    for datafile in os.listdir(direc):\n",
      "        if datafile == \"DS.Store\": continue\n",
      "        # extract id and true class (if available) from filename\n",
      "        id_str,clazz = datafile.split('.')[:2]\n",
      "        ids.append(id_str)\n",
      "        # add target class if this is training data\n",
      "        try:\n",
      "            classes.append(util.malware_classes.index(clazz))\n",
      "        except ValueError:\n",
      "            # we should only fail to find the label in our list of malware classes\n",
      "            # if this is test data, which always has an \"X\" label\n",
      "            assert clazz == \"X\"\n",
      "            classes.append(-1)\n",
      "        rowfd = {}\n",
      "        # parse file as an xml document\n",
      "        tree = ET.parse(os.path.join(direc,datafile))\n",
      "        # accumulate features\n",
      "        [rowfd.update(ff(tree)) for ff in ffs]\n",
      "        fds.append(rowfd)\n",
      "        \n",
      "        i += 1\n",
      "        if i%100 == 0: \n",
      "            print \"Progress: \" + str(i) + \"/\" + N\n",
      "            sys.stdout.flush()\n",
      "        \n",
      "    X,feat_dict = make_design_mat(fds,global_feat_dict)\n",
      "    return X, feat_dict, np.array(classes), ids\n",
      "\n",
      "\n",
      "def make_design_mat(fds, global_feat_dict = None):\n",
      "    \"\"\"\n",
      "    arguments:\n",
      "      fds is a list of feature dicts (one for each row).\n",
      "      global_feat_dict is a dictionary mapping feature_names to column-numbers; it\n",
      "      should only be provided when extracting features from test data, so that \n",
      "      the columns of the test matrix align correctly.\n",
      "       \n",
      "    returns: \n",
      "        a sparse NxD design matrix, where N == len(fds) and D is the number of\n",
      "        the union of features defined in any of the fds \n",
      "    \"\"\"\n",
      "    if global_feat_dict is None:\n",
      "        all_feats = set()\n",
      "        [all_feats.update(fd.keys()) for fd in fds]\n",
      "        feat_dict = dict([(feat, i) for i, feat in enumerate(sorted(all_feats))])\n",
      "    else:\n",
      "        feat_dict = global_feat_dict\n",
      "        \n",
      "    cols = []\n",
      "    rows = []\n",
      "    data = []        \n",
      "    for i in xrange(len(fds)):\n",
      "        temp_cols = []\n",
      "        temp_data = []\n",
      "        for feat,val in fds[i].iteritems():\n",
      "            try:\n",
      "                # update temp_cols iff update temp_data\n",
      "                temp_cols.append(feat_dict[feat])\n",
      "                temp_data.append(val)\n",
      "            except KeyError as ex:\n",
      "                if global_feat_dict is not None:\n",
      "                    pass  # new feature in test data; nbd\n",
      "                else:\n",
      "                    raise ex\n",
      "\n",
      "        # all fd's features in the same row\n",
      "        k = len(temp_cols)\n",
      "        cols.extend(temp_cols)\n",
      "        data.extend(temp_data)\n",
      "        rows.extend([i]*k)\n",
      "\n",
      "    assert len(cols) == len(rows) and len(rows) == len(data)\n",
      "   \n",
      "\n",
      "    X = sparse.csr_matrix(\n",
      "    (np.array(data),(np.array(rows), np.array(cols))), \n",
      "    shape=(len(fds), len(feat_dict))\n",
      "    )\n",
      "    \n",
      "    return X, feat_dict\n",
      "    \n",
      "################################################"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "################################\n",
      "#### 3. Feature Vectors\n",
      "################################\n",
      "\n",
      "## Here are two example feature-functions. They each take an xml.etree.ElementTree object, \n",
      "# (i.e., the result of parsing an xml file) and returns a dictionary mapping \n",
      "# feature-names to numeric values.\n",
      "## TODO: \n",
      "##    1. DLL Type and Address.\n",
      "##    2. enum_values, explorer\n",
      "##    3. create_namedpipe\n",
      "##    4. create_thread_remote\n",
      "\n",
      "\n",
      "def get_all_keys(tree):\n",
      "    key_list = Counter()\n",
      "    tag_exclusion_set = [\"load_dll\"]\n",
      "    \n",
      "    in_all_section = False\n",
      "\n",
      "    for el in tree.iter():\n",
      "        # ignore everything outside the \"all_section\" element\n",
      "        if el.tag == \"all_section\" and not in_all_section:\n",
      "            in_all_section = True\n",
      "        elif el.tag == \"all_section\" and in_all_section:\n",
      "            in_all_section = False\n",
      "        elif in_all_section:\n",
      "            #if el.tag in tag_set\n",
      "            for key in el.keys():\n",
      "                if key not in tag_exclusion_set:\n",
      "                    key_list_name = \\\n",
      "                        (el.tag + \"_\" + key + \"-\" + el.get(key)).lower()\n",
      "                    key_list[key_list_name] += 1\n",
      "    return key_list\n",
      "\n",
      "\n",
      "def dll_type(tree, name_only = False):\n",
      "    #type and address of loaded DLLs\n",
      "    dll_list = {\"name\": [], \"extn\": [], \"addr\": []} \n",
      "\n",
      "    for el in tree.iter():\n",
      "        # obtain DLL target in element\n",
      "        if el.tag == \"load_dll\":\n",
      "            dll_name = el.get('filename')\n",
      "            #split filename and file_address\n",
      "            try:\n",
      "                key_bag = dll_name.split(\"\\\\\")\n",
      "                dll_name = \"dll_name-\" + key_bag[len(key_bag) - 1]\n",
      "                dll_addr = \"dll_addr-\" + \"//\".join(key_bag[:(len(key_bag) - 1)])\n",
      "            except AttributeError:\n",
      "                dll_name = \"dll_name-DLL_FILE_NOT_SPECIFIED\"\n",
      "                dll_addr = \"dll_addr-\" + \"//\".join(key_bag)\n",
      "            \n",
      "            if len(dll_name.split(\".\")) == 2:\n",
      "                key_bag = dll_name.split(\".\")\n",
      "                dll_name = key_bag[0]\n",
      "                dll_extn = \"dll_extn-\" + key_bag[1]\n",
      "            else:\n",
      "                dll_extn = \"dll_extn-\"\n",
      "            \n",
      "            dll_name = dll_name.lower()\n",
      "            dll_extn = dll_extn.lower()\n",
      "            dll_addr = dll_addr.lower()\n",
      "            #TODO: convert to lower case\n",
      "            dll_list[\"name\"].append(dll_name)\n",
      "            dll_list[\"extn\"].append(dll_extn)\n",
      "            dll_list[\"addr\"].append(dll_addr)\n",
      "\n",
      "    dll_list[\"name\"] = stats.itemfreq(dll_list[\"name\"])\n",
      "    dll_list[\"extn\"] = stats.itemfreq(dll_list[\"extn\"])    \n",
      "    dll_list[\"addr\"] = stats.itemfreq(dll_list[\"addr\"])    \n",
      "    dll_list_join = pd.concatenate([dll_list[\"name\"], \\\n",
      "                    dll_list[\"extn\"], dll_list[\"addr\"]])\n",
      "\n",
      "    dll_name_counter = Counter()\n",
      "    for item in dll_list_join: \n",
      "        dll_name_counter[item[0]] = int(item[1])\n",
      "\n",
      "    return dll_name_counter\n",
      "\n",
      "\n",
      "def call_freq(tree, name_only = False):\n",
      "    \"\"\"\n",
      "    arguments:\n",
      "      tree is an xml.etree.ElementTree object\n",
      "    returns:\n",
      "      a dictionary mapping 'first_call-x' to 1 if x was the first system call\n",
      "      made, and 'last_call-y' to 1 if y was the last system call made. \n",
      "      (in other words, it returns a dictionary indicating what the first and \n",
      "      last system calls made by an executable were.)\n",
      "    \"\"\"\n",
      "    callz = []\n",
      "    in_all_section = False\n",
      "    first = True # is this the first system call\n",
      "    last_call = None # keep track of last call we've seen\n",
      "    for el in tree.iter():\n",
      "        # ignore everything outside the \"all_section\" element\n",
      "        if el.tag == \"all_section\" and not in_all_section:\n",
      "            in_all_section = True\n",
      "        elif el.tag == \"all_section\" and in_all_section:\n",
      "            in_all_section = False\n",
      "        elif in_all_section:\n",
      "            callz.append(el.tag)\n",
      "\n",
      "    # finally, count the frequencies\n",
      "    freqList = stats.itemfreq(callz)   \n",
      "    \n",
      "    if name_only == True:        \n",
      "        c = set(callz)\n",
      "    else: \n",
      "        c = Counter()\n",
      "        for item in freqList: c[\"sys_call-\" +item[0]] = int(item[1])\n",
      "\n",
      "    return c\n",
      "\n",
      "\n",
      "def call_eigen(tree, call_dict, name_only = False):\n",
      "    #TODO: Implement this!\n",
      "    c = []\n",
      "    return c\n",
      "\n",
      "\n",
      "def first_last_system_call_feats(tree):\n",
      "    \"\"\"\n",
      "    arguments:\n",
      "      tree is an xml.etree.ElementTree object\n",
      "    returns:\n",
      "      a dictionary mapping 'first_call-x' to 1 if x was the first system call\n",
      "      made, and 'last_call-y' to 1 if y was the last system call made. \n",
      "      (in other words, it returns a dictionary indicating what the first and \n",
      "      last system calls made by an executable were.)\n",
      "    \"\"\"\n",
      "    c = Counter()\n",
      "    in_all_section = False\n",
      "    first = True # is this the first system call\n",
      "    last_call = None # keep track of last call we've seen\n",
      "    for el in tree.iter():\n",
      "        # ignore everything outside the \"all_section\" element\n",
      "        if el.tag == \"all_section\" and not in_all_section:\n",
      "            in_all_section = True\n",
      "        elif el.tag == \"all_section\" and in_all_section:\n",
      "            in_all_section = False\n",
      "        elif in_all_section:\n",
      "            if first:\n",
      "                c[\"first_call-\"+el.tag] = 1\n",
      "                first = False\n",
      "            last_call = el.tag  # update last call seen\n",
      "            \n",
      "    # finally, mark last call seen\n",
      "    c[\"last_call-\"+last_call] = 1\n",
      "    return c\n",
      "\n",
      "def system_call_count_feats(tree):\n",
      "    \"\"\"\n",
      "    arguments:\n",
      "      tree is an xml.etree.ElementTree object\n",
      "    returns:\n",
      "      a dictionary mapping 'num_system_calls' to the number of system_calls\n",
      "      made by an executable (summed over all processes)\n",
      "    \"\"\"\n",
      "    c = Counter()\n",
      "    in_all_section = False\n",
      "    for el in tree.iter():\n",
      "        # ignore everything outside the \"all_section\" element\n",
      "        if el.tag == \"all_section\" and not in_all_section:\n",
      "            in_all_section = True\n",
      "        elif el.tag == \"all_section\" and in_all_section:\n",
      "            in_all_section = False\n",
      "        elif in_all_section:\n",
      "            c['num_system_calls'] += 1\n",
      "    return c\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "################################\n",
      "#### 4. Variables of Interest\n",
      "################################\n",
      "\n",
      "\n",
      "def call_type(direc):\n",
      "    names = set() # list of feature dicts\n",
      "    for datafile in os.listdir(direc):\n",
      "        if datafile == \"DS.Store\": continue\n",
      "        # parse file as an xml document\n",
      "        tree = ET.parse(os.path.join(direc,datafile))\n",
      "        # accumulate features\n",
      "        newnames = call_freq(tree, name_only = True)\n",
      "        names = names.union(newnames)\n",
      "    out_names = names\n",
      "    return out_names\n",
      "\n",
      "def call_freq_emp(direc):\n",
      "    names = dict() # list of feature dicts\n",
      "    for datafile in os.listdir(direc):\n",
      "        if datafile == \"DS.Store\": continue\n",
      "        # parse file as an xml document\n",
      "        tree = ET.parse(os.path.join(direc,datafile))\n",
      "        # accumulate features\n",
      "        newnames = call_freq(tree)\n",
      "        for k in newnames.iterkeys():\n",
      "            if k in names: names[k] = names[k] + newnames[k]\n",
      "            else: names[k] = newnames[k]\n",
      "            \n",
      "    out_names = names\n",
      "    return out_names\n",
      "    \n",
      "def call_freq_byType(direc):\n",
      "    #initiate class dependent dictionary\n",
      "    name_byType = dict() # list of feature dicts\n",
      "    for TypeName in util.malware_classes:\n",
      "        name_byType[TypeName] = dict()\n",
      " \n",
      "    for datafile in os.listdir(direc):\n",
      "        if datafile == \"DS.Store\": continue\n",
      "        # extract id and true class (if available) from filename\n",
      "        id_str,clazz = datafile.split('.')[:2]\n",
      "        # parse file as an xml document\n",
      "        tree = ET.parse(os.path.join(direc,datafile))\n",
      "        # accumulate features: first create new feature\n",
      "        newnames = call_freq(tree)\n",
      "        # \n",
      "        curNames = name_byType[clazz]\n",
      "        for k in newnames.iterkeys():\n",
      "            if k in curNames: \n",
      "                curNames[k] = curNames[k] + newnames[k]\n",
      "            else: curNames[k] = newnames[k]\n",
      "        name_byType[clazz] = curNames\n",
      "        \n",
      "    out_names = name_byType\n",
      "    return out_names\n",
      "    \n",
      "def dll_type_2(tree, name_only = False):\n",
      "    dll_list = {\"name\": [], \"addr\": []} \n",
      "\n",
      "    for el in tree.iter():\n",
      "        # obtain DLL target in element\n",
      "        if el.tag == \"load_dll\":\n",
      "            dll_name = el.get('filename')\n",
      "            #split filename and file_address\n",
      "            key_bag = dll_name.split(\"\\\\\")\n",
      "            \n",
      "            dll_name = key_bag[len(key_bag) - 1]\n",
      "            dll_addr = \"//\".join(key_bag[:(len(key_bag) - 1)])\n",
      "            #TODO: convert to lower case\n",
      "\n",
      "            dll_list[\"name\"].append(dll_name)\n",
      "            dll_list[\"addr\"].append(dll_addr)\n",
      "\n",
      "    dll_list[\"name\"] = stats.itemfreq(dll_list[\"name\"])\n",
      "    dll_list[\"addr\"] = stats.itemfreq(dll_list[\"addr\"])    \n",
      "    dll_list_join = concatenate([dll_list[\"name\"], dll_list[\"addr\"]])\n",
      "\n",
      "    dll_name_counter = Counter()\n",
      "    for item in dll_list_join: \n",
      "        dll_name_counter[item[0]] = int(item[1])\n",
      "\n",
      "    return dll_name_counter\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def call_eigen(tree, call_dict, name_only = False):\n",
      "    #TODO: Implement this!\n",
      "    c = []\n",
      "    return c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_dir = \"train\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ffs = [first_last_system_call_feats, system_call_count_feats,call_freq, dll_type]#, get_all_keys]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train,global_feat_dict,t_train,train_ids = extract_feats(ffs, train_dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "global name 'concatenate' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-16-a2610daf1d5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mglobal_feat_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-3-e2a5e2d95399>\u001b[0m in \u001b[0;36mextract_feats\u001b[0;34m(ffs, direc, global_feat_dict)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# accumulate features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mrowfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mff\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mffs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-4-71536c05ea24>\u001b[0m in \u001b[0;36mdll_type\u001b[0;34m(tree, name_only)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mdll_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"extn\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemfreq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdll_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"extn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mdll_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"addr\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemfreq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdll_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"addr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mdll_list_join\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdll_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                     \u001b[0mdll_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"extn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdll_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"addr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mdll_name_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: global name 'concatenate' is not defined"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}